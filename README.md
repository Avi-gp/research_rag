# ğŸ§  ResearchMind
RAG-Powered Research Paper Q&A and Summarization System

## ğŸ“Œ Overview
**ResearchMind** is a modern **Streamlit + FastAPI** application that helps researchers:
- ğŸ“¤ Upload and process research papers (PDFs)  
- â“ Ask AI-powered questions with citations & similarity scores  
- ğŸ“‹ Generate smart summaries (executive, key findings, methodology, etc.)  
- ğŸ“Š Monitor system statistics and embeddings  
- ğŸ—‚ Manage stored PDFs and vector databases  

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```bash
git clone 'https://github.com/Avi-gp/research_rag.git'

cd research_rag
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Add API Key(s)

Create a .env file in the root directory and add your API keys. For example:
```bash
GOOGLE_API_KEY=your_gemini_key_here (For LLM)

NVIDIA_API_KEY=your_nvidia_api_key (FOR Embedding Model)

```

If you want to use other Embedding Model or LLLM make changes in respective files

### 4ï¸âƒ£ Start the Backend (FastAPI)
```bash
python api/main.py
```

### 5ï¸âƒ£ Run the Frontend (Streamlit)
```bash
streamlit run ui/app.py
```

### ğŸ”‘ Features

âœ… Upload multiple research papers (PDFs)

âœ… RAG-based Q&A with similarity threshold tuning

âœ… Generate focused or comprehensive summaries

âœ… View system statistics & embeddings info

âœ… Manage database (clear PDFs, vector store, or reset system)

### ğŸ“‚ Project Structure
```bash
â”œâ”€â”€ api/               # FastAPI backend
â”œâ”€â”€ config/            # Settings and configurations
â”œâ”€â”€ data/              # Stored PDFs and vector database
â”œâ”€â”€ services/          # # Core logic for LLM, PDF processing, vector store, and RAG pipeline
â”œâ”€â”€ ui/app.py          # Streamlit frontend
â””â”€â”€ requirements.txt   # Dependencies
```

### âš ï¸ Notes

Make sure the FastAPI server is running before using Streamlit.

Only PDF files are supported for ingestion.

Database management actions (resets, clears) are irreversible.


